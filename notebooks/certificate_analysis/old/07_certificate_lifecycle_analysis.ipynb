{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34c14a4-2410-4082-9626-e69e1b78c11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing website_data...\n",
      "Analysis complete for website_data\n",
      "\n",
      "Analyzing normal_sites...\n",
      "Analysis complete for normal_sites\n"
     ]
    }
   ],
   "source": [
    "# Certificate Lifecycle Analysis\n",
    "# Location: RAPIDS/notebooks/certificate_analysis/07_certificate_lifecycle_analysis.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple\n",
    "import calendar\n",
    "import re  # 正規表現モジュールをインポート\n",
    "\n",
    "class CertificateLifecycleAnalyzer:\n",
    "    \"\"\"Analyzer for SSL certificate lifecycle patterns between phishing and normal sites\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = '/home/asomura/waseda/nextstep/RAPIDS/config/database.json'):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with configuration and setup directories\n",
    "        \n",
    "        Args:\n",
    "            config_path: Path to database configuration file\n",
    "        \"\"\"\n",
    "        self.setup_environment(config_path)\n",
    "        self.setup_logging()\n",
    "        \n",
    "    def setup_environment(self, config_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Setup analysis environment and load configuration\n",
    "        \n",
    "        Args:\n",
    "            config_path: Path to configuration file\n",
    "        \"\"\"\n",
    "        # Load database configuration\n",
    "        with open(config_path) as f:\n",
    "            self.config = json.load(f)['database']\n",
    "            \n",
    "        # Setup directory structure\n",
    "        self.base_dir = Path('/home/asomura/waseda/nextstep/RAPIDS')\n",
    "        self.output_dir = self.base_dir / 'reports' / 'lifecycle_analysis'\n",
    "        self.data_dir = self.base_dir / 'data' / 'processed'\n",
    "        \n",
    "        for dir_path in [self.output_dir, self.data_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        # Set plot style\n",
    "        # plt.style.use('seaborn')\n",
    "        # self.colors = {'phishing': '#FF6B6B', 'normal': '#4ECDC4'}\n",
    "\n",
    "        # Set plot style using sns\n",
    "        sns.set_theme()  # seabornのデフォルトテーマを設定\n",
    "        self.colors = {'phishing': '#FF6B6B', 'normal': '#4ECDC4'}\n",
    "    \n",
    "    def setup_logging(self) -> None:\n",
    "        \"\"\"Configure logging settings\"\"\"\n",
    "        log_dir = self.base_dir / 'data' / 'logs'\n",
    "        log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        logging.basicConfig(\n",
    "            filename=log_dir / f'lifecycle_analysis_{self.timestamp}.log',\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def get_database_engine(self, db_name: str) -> create_engine:\n",
    "        \"\"\"\n",
    "        Create database connection engine\n",
    "        \n",
    "        Args:\n",
    "            db_name: Name of the database to connect\n",
    "            \n",
    "        Returns:\n",
    "            SQLAlchemy engine\n",
    "        \"\"\"\n",
    "        host = 'localhost' if db_name == 'website_data' else '192.168.1.92'\n",
    "        return create_engine(\n",
    "            f\"postgresql://{self.config['user']}:{self.config['password']}@{host}/{db_name}\"\n",
    "        )\n",
    "\n",
    "    def extract_certificate_data(self, db_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract relevant certificate data for lifecycle analysis\n",
    "        \n",
    "        Args:\n",
    "            db_name: Database name to query\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame containing certificate lifecycle data\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Extracting certificate data from {db_name}\")\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            domain,\n",
    "            https_certificate_issuer,\n",
    "            https_certificate_expiry,\n",
    "            last_update,\n",
    "            domain_registrar,\n",
    "            https_certificate_domain,\n",
    "            https_certificate_body\n",
    "        FROM website_data \n",
    "        WHERE status = 7 \n",
    "        AND https_certificate_issuer IS NOT NULL\n",
    "        AND last_update IS NOT NULL\n",
    "        \"\"\"\n",
    "        \n",
    "        engine = self.get_database_engine(db_name)\n",
    "        return pd.read_sql_query(query, engine)\n",
    "        \n",
    "    def analyze_lifecycle_patterns(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze certificate lifecycle patterns\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing certificate data\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing analysis results\n",
    "        \"\"\"\n",
    "        df['last_update'] = pd.to_datetime(df['last_update'])\n",
    "        \n",
    "        # Extract expiry period from certificate expiry text\n",
    "        df['expiry_days'] = df['https_certificate_expiry'].apply(self._extract_expiry_period)\n",
    "        \n",
    "        # Analyze temporal patterns\n",
    "        temporal_patterns = {\n",
    "            'weekday_distribution': df['last_update'].dt.dayofweek.value_counts().to_dict(),\n",
    "            'hour_distribution': df['last_update'].dt.hour.value_counts().to_dict(),\n",
    "            'month_distribution': df['last_update'].dt.month.value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        # Analyze expiry patterns\n",
    "        expiry_patterns = {\n",
    "            'expiry_distribution': df['expiry_days'].value_counts().to_dict(),\n",
    "            'short_term_ratio': len(df[df['expiry_days'] < 90]) / len(df),\n",
    "            'medium_term_ratio': len(df[(df['expiry_days'] >= 90) & (df['expiry_days'] < 365)]) / len(df),\n",
    "            'long_term_ratio': len(df[df['expiry_days'] >= 365]) / len(df)\n",
    "        }\n",
    "        \n",
    "        # Analyze issuer patterns\n",
    "        issuer_patterns = self._analyze_issuer_patterns(df)\n",
    "        \n",
    "        return {\n",
    "            'temporal_patterns': temporal_patterns,\n",
    "            'expiry_patterns': expiry_patterns,\n",
    "            'issuer_patterns': issuer_patterns\n",
    "        }\n",
    "    \n",
    "    def _extract_expiry_period(self, expiry_text: str) -> int:\n",
    "        \"\"\"\n",
    "        Extract certificate validity period in days\n",
    "        \n",
    "        Args:\n",
    "            expiry_text: Text containing expiry information\n",
    "            \n",
    "        Returns:\n",
    "            Number of days until expiry\n",
    "        \"\"\"\n",
    "        if pd.isna(expiry_text):\n",
    "            return 0\n",
    "            \n",
    "        # Extract days from common patterns\n",
    "        days_pattern = r'(\\d+)\\s*(?:days?|d)'\n",
    "        match = re.search(days_pattern, str(expiry_text), re.IGNORECASE)\n",
    "        \n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        return 0\n",
    "        \n",
    "    def _analyze_issuer_patterns(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze patterns in certificate issuer behavior\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing certificate data\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing issuer pattern analysis\n",
    "        \"\"\"\n",
    "        issuer_expiry = df.groupby('https_certificate_issuer')['expiry_days'].agg(['mean', 'std', 'count'])\n",
    "        top_issuers = issuer_expiry.nlargest(5, 'count')\n",
    "        \n",
    "        return {\n",
    "            'top_issuers': top_issuers.to_dict(),\n",
    "            'issuer_timing': df.groupby('https_certificate_issuer')['last_update'].agg(\n",
    "                lambda x: x.dt.dayofweek.mode().iloc[0]\n",
    "            ).to_dict()\n",
    "        }\n",
    "        \n",
    "    def visualize_patterns(self, patterns: Dict, db_name: str) -> None:\n",
    "        \"\"\"\n",
    "        Create visualizations for lifecycle patterns\n",
    "        \n",
    "        Args:\n",
    "            patterns: Dictionary containing analysis results\n",
    "            db_name: Name of the database analyzed\n",
    "        \"\"\"\n",
    "        # Create temporal pattern plots\n",
    "        self._plot_temporal_patterns(patterns['temporal_patterns'], db_name)\n",
    "        \n",
    "        # Create expiry pattern plots\n",
    "        self._plot_expiry_patterns(patterns['expiry_patterns'], db_name)\n",
    "        \n",
    "        # Create issuer pattern plots\n",
    "        self._plot_issuer_patterns(patterns['issuer_patterns'], db_name)\n",
    "        \n",
    "    def _plot_temporal_patterns(self, temporal_patterns: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create temporal pattern visualizations\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Weekday distribution\n",
    "        weekdays = [calendar.day_name[i] for i in range(7)]\n",
    "        weekday_counts = [temporal_patterns['weekday_distribution'].get(i, 0) for i in range(7)]\n",
    "        \n",
    "        ax1.bar(weekdays, weekday_counts, color=self.colors['phishing'])\n",
    "        ax1.set_title(f'Certificate Issuance by Day of Week - {db_name}')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Hour distribution\n",
    "        hours = list(range(24))\n",
    "        hour_counts = [temporal_patterns['hour_distribution'].get(i, 0) for i in hours]\n",
    "        \n",
    "        ax2.plot(hours, hour_counts, color=self.colors['phishing'])\n",
    "        ax2.set_title(f'Certificate Issuance by Hour - {db_name}')\n",
    "        ax2.set_xlabel('Hour of Day')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'temporal_patterns_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def _plot_expiry_patterns(self, expiry_patterns: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create expiry pattern visualizations\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Plot expiry period distribution\n",
    "        expiry_data = pd.Series(expiry_patterns['expiry_distribution'])\n",
    "        expiry_data.plot(kind='hist', bins=50, color=self.colors['phishing'])\n",
    "        \n",
    "        plt.title(f'Certificate Validity Period Distribution - {db_name}')\n",
    "        plt.xlabel('Days until Expiry')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'expiry_patterns_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def _plot_issuer_patterns(self, issuer_patterns: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create issuer pattern visualizations\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot top issuers by certificate count\n",
    "        top_issuers = pd.DataFrame(issuer_patterns['top_issuers'])\n",
    "        top_issuers['count'].plot(kind='bar', color=self.colors['phishing'])\n",
    "        \n",
    "        plt.title(f'Top Certificate Issuers - {db_name}')\n",
    "        plt.xlabel('Issuer')\n",
    "        plt.ylabel('Certificate Count')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'issuer_patterns_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    analyzer = CertificateLifecycleAnalyzer()\n",
    "    \n",
    "    results = {}\n",
    "    for db_name in ['website_data', 'normal_sites']:\n",
    "        print(f\"\\nAnalyzing {db_name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Extract and analyze data\n",
    "            df = analyzer.extract_certificate_data(db_name)\n",
    "            patterns = analyzer.analyze_lifecycle_patterns(df)\n",
    "            \n",
    "            # Create visualizations\n",
    "            analyzer.visualize_patterns(patterns, db_name)\n",
    "            \n",
    "            # Store results\n",
    "            results[db_name] = patterns\n",
    "            \n",
    "            # Save results to JSON\n",
    "            output_path = analyzer.data_dir / f'lifecycle_patterns_{db_name}_{analyzer.timestamp}.json'\n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(patterns, f, indent=2)\n",
    "            \n",
    "            print(f\"Analysis complete for {db_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {db_name}: {str(e)}\")\n",
    "            analyzer.logger.error(f\"Error analyzing {db_name}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1c711-1ebb-48ed-9416-f0feda52346c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
