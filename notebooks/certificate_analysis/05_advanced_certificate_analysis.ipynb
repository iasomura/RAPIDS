{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5bf4a53-43bf-45ce-ae71-ff653e6be458",
   "metadata": {},
   "source": [
    "# インポートと初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac85870-8d32-4373-922a-5e536f708e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008e0e0-6f42-4dca-85b2-6889110f7367",
   "metadata": {},
   "source": [
    "# アナライザークラスの全定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710ac4b9-b92c-428d-8e11-57779e291868",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCertificateAnalyzer:\n",
    "    \"\"\"Advanced SSL certificate analyzer with comprehensive feature extraction and analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str):\n",
    "        \"\"\"Initialize the analyzer with configuration and setup\"\"\"\n",
    "        self.setup_environment(config_path)\n",
    "        self.setup_logging()\n",
    "        \n",
    "    def setup_environment(self, config_path: str) -> None:\n",
    "        \"\"\"Setup analysis environment and load configuration\"\"\"\n",
    "        with open(config_path) as f:\n",
    "            self.config = json.load(f)['database']\n",
    "            \n",
    "        self.base_dir = Path('/home/asomura/waseda/nextstep/RAPIDS')\n",
    "        self.output_dir = self.base_dir / 'reports' / 'certificate_analysis'\n",
    "        self.data_dir = self.base_dir / 'data' / 'processed'\n",
    "        \n",
    "        for dir_path in [self.output_dir, self.data_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "    def setup_logging(self) -> None:\n",
    "        \"\"\"Configure logging settings\"\"\"\n",
    "        log_dir = self.base_dir / 'data' / 'logs'\n",
    "        log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        logging.basicConfig(\n",
    "            filename=log_dir / f'advanced_cert_analysis_{self.timestamp}.log',\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def get_database_connection(self, db_name: str) -> create_engine:\n",
    "        \"\"\"Create database connection\"\"\"\n",
    "        host = 'localhost' if db_name == 'website_data' else '192.168.1.92'\n",
    "        return create_engine(\n",
    "            f\"postgresql://{self.config['user']}:{self.config['password']}@{host}/{db_name}\"\n",
    "        )\n",
    "\n",
    "    def extract_certificate_data(self, db_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Extract certificate data from database\"\"\"\n",
    "        self.logger.info(f\"Extracting certificate data from {db_name}\")\n",
    "        \n",
    "        engine = self.get_database_connection(db_name)\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            domain,\n",
    "            https_certificate_issuer,\n",
    "            https_certificate_domain,\n",
    "            https_certificate_expiry,\n",
    "            https_certificate_public_key,\n",
    "            https_certificate_signature_algorithm,\n",
    "            https_certificate_extensions,\n",
    "            https_certificate_body,\n",
    "            domain_registrar,\n",
    "            last_update,\n",
    "            whois_domain,\n",
    "            dig_info_a,\n",
    "            dig_info_mx,\n",
    "            dig_info_ns,\n",
    "            ip_organization\n",
    "        FROM website_data \n",
    "        WHERE status = 7 \n",
    "        AND https_certificate_issuer IS NOT NULL\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql_query(query, engine)\n",
    "\n",
    "    def _extract_basic_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract basic certificate features\"\"\"\n",
    "        return {\n",
    "            'total_certs': int(len(df)),\n",
    "            'issuer_distribution': df['https_certificate_issuer'].value_counts().to_dict(),\n",
    "            'algorithm_distribution': df['https_certificate_signature_algorithm'].value_counts().to_dict(),\n",
    "            'registrar_distribution': df['domain_registrar'].value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_temporal_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract temporal patterns and features\"\"\"\n",
    "        df['last_update'] = pd.to_datetime(df['last_update'])\n",
    "        \n",
    "        daily_counts = df.groupby(df['last_update'].dt.date).size()\n",
    "        monthly_counts = df.groupby([\n",
    "            df['last_update'].dt.year,\n",
    "            df['last_update'].dt.month\n",
    "        ]).size()\n",
    "        \n",
    "        return {\n",
    "            'daily_counts': {str(k): int(v) for k, v in daily_counts.items()},\n",
    "            'monthly_counts': {f\"{k[0]}-{k[1]}\": int(v) for k, v in monthly_counts.items()},\n",
    "            'weekday_distribution': df['last_update'].dt.dayofweek.value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_structural_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract structural certificate features\"\"\"\n",
    "        domain_levels = df['domain'].str.count(r'\\.') + 1\n",
    "        has_wildcard = df['https_certificate_domain'].str.contains(r'\\*', regex=True).fillna(False)\n",
    "        \n",
    "        return {\n",
    "            'domain_levels': domain_levels.value_counts().to_dict(),\n",
    "            'has_wildcard': has_wildcard.value_counts().to_dict(),\n",
    "            'cert_domain_match': df.apply(\n",
    "                lambda x: str(x['domain']).lower() in str(x['https_certificate_domain']).lower()\n",
    "                if pd.notnull(x['https_certificate_domain']) else False,\n",
    "                axis=1\n",
    "            ).value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_security_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract security-related features\"\"\"\n",
    "        key_strength = df['https_certificate_public_key'].apply(self._analyze_key_strength)\n",
    "        return {\n",
    "            'key_strength': [k for k in key_strength],\n",
    "            'is_self_signed': df['https_certificate_issuer'].str.contains(\n",
    "                'self signed', case=False\n",
    "            ).fillna(False).value_counts().to_dict(),\n",
    "            'uses_sha1': df['https_certificate_signature_algorithm'].str.contains(\n",
    "                'sha1', case=False\n",
    "            ).fillna(False).value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _analyze_key_strength(self, key_info: str) -> Dict:\n",
    "        \"\"\"Analyze public key strength\"\"\"\n",
    "        if pd.isna(key_info):\n",
    "            return {'type': 'unknown', 'strength': 0}\n",
    "            \n",
    "        key_info = str(key_info).upper()\n",
    "        \n",
    "        if 'RSA' in key_info:\n",
    "            match = re.search(r'(\\d+)\\s*(?:BIT|BITS)?', key_info)\n",
    "            return {\n",
    "                'type': 'RSA',\n",
    "                'strength': int(match.group(1)) if match else 0\n",
    "            }\n",
    "        elif any(ec in key_info for ec in ['EC', 'ECDSA']):\n",
    "            match = re.search(r'(\\d+)[Kk]?', key_info)\n",
    "            return {\n",
    "                'type': 'EC',\n",
    "                'strength': int(match.group(1)) if match else 0\n",
    "            }\n",
    "        \n",
    "        return {'type': 'unknown', 'strength': 0}\n",
    "\n",
    "    def analyze_certificates(self, db_name: str) -> Dict:\n",
    "        \"\"\"Perform comprehensive certificate analysis\"\"\"\n",
    "        self.logger.info(f\"Starting analysis for {db_name}\")\n",
    "        \n",
    "        try:\n",
    "            df = self.extract_certificate_data(db_name)\n",
    "            \n",
    "            features = {\n",
    "                'basic': self._extract_basic_features(df),\n",
    "                'temporal': self._extract_temporal_features(df),\n",
    "                'structural': self._extract_structural_features(df),\n",
    "                'security': self._extract_security_features(df)\n",
    "            }\n",
    "            \n",
    "            self._save_processed_data(features, db_name)\n",
    "            self._generate_visualizations(features, db_name)\n",
    "            \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing certificates for {db_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _process_for_serialization(self, obj: Any) -> Any:\n",
    "        \"\"\"Process objects for JSON serialization\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            return {str(k): self._process_for_serialization(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (pd.Series, pd.DataFrame)):\n",
    "            return obj.to_dict()\n",
    "        elif isinstance(obj, (np.integer, np.floating)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (date, datetime)):\n",
    "            return str(obj)\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [self._process_for_serialization(x) for x in obj]\n",
    "        return obj\n",
    "\n",
    "    def _save_processed_data(self, features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Save processed data to files\"\"\"\n",
    "        try:\n",
    "            output_path = self.data_dir / f'cert_features_{db_name}_{self.timestamp}.json'\n",
    "            processed_features = self._process_for_serialization(features)\n",
    "            \n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(processed_features, f, indent=2, default=str)\n",
    "                \n",
    "            self.logger.info(f\"Saved processed data to {output_path}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving processed data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _generate_visualizations(self, features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Generate and save visualizations\"\"\"\n",
    "        try:\n",
    "            self._plot_temporal_patterns(features['temporal'], db_name)\n",
    "            self._plot_security_patterns(features['security'], db_name)\n",
    "            self._plot_structural_patterns(features['structural'], db_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error generating visualizations: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _plot_temporal_patterns(self, temporal_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create temporal analysis plots\"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        monthly_data = {\n",
    "            datetime.strptime(k, \"%Y-%m\"): v \n",
    "            for k, v in temporal_features['monthly_counts'].items()\n",
    "        }\n",
    "        dates = sorted(monthly_data.keys())\n",
    "        counts = [monthly_data[date] for date in dates]\n",
    "        \n",
    "        plt.plot(range(len(counts)), counts)\n",
    "        plt.title(f'Monthly Certificate Counts - {db_name}')\n",
    "        plt.xlabel('Month Index')\n",
    "        plt.ylabel('Number of Certificates')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'temporal_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_security_patterns(self, security_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create security analysis plots\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        key_strengths = [x['strength'] for x in security_features['key_strength'] if x['strength'] > 0]\n",
    "        if key_strengths:\n",
    "            plt.hist(key_strengths, bins=20, edgecolor='black')\n",
    "            plt.title(f'Key Strength Distribution - {db_name}')\n",
    "            plt.xlabel('Key Strength (bits)')\n",
    "            plt.ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'security_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_structural_patterns(self, structural_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create structural analysis plots\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        levels = list(structural_features['domain_levels'].keys())\n",
    "        counts = list(structural_features['domain_levels'].values())\n",
    "        \n",
    "        plt.bar(levels, counts)\n",
    "        plt.title(f'Domain Level Distribution - {db_name}')\n",
    "        plt.xlabel('Domain Levels')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'structural_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c720ee-2137-47ab-9efd-765f8b291002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "300b959e-e1ba-4813-a2d0-cfe83520cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d008dadf-e16e-4dd9-9765-9989ce7c6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65732c4b-856f-4f77-a6da-aa8f826d2144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCertificateAnalyzer:\n",
    "    \"\"\"Advanced SSL certificate analyzer with comprehensive feature extraction and analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str):\n",
    "        \"\"\"Initialize the analyzer with configuration and setup\"\"\"\n",
    "        self.setup_environment(config_path)\n",
    "        self.setup_logging()\n",
    "        \n",
    "    def setup_environment(self, config_path: str) -> None:\n",
    "        \"\"\"Setup analysis environment and load configuration\"\"\"\n",
    "        with open(config_path) as f:\n",
    "            self.config = json.load(f)['database']\n",
    "            \n",
    "        self.base_dir = Path('/home/asomura/waseda/nextstep/RAPIDS')\n",
    "        self.output_dir = self.base_dir / 'reports' / 'certificate_analysis'\n",
    "        self.data_dir = self.base_dir / 'data' / 'processed'\n",
    "        \n",
    "        for dir_path in [self.output_dir, self.data_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "    def setup_logging(self) -> None:\n",
    "        \"\"\"Configure logging settings\"\"\"\n",
    "        log_dir = self.base_dir / 'data' / 'logs'\n",
    "        log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        logging.basicConfig(\n",
    "            filename=log_dir / f'advanced_cert_analysis_{self.timestamp}.log',\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def get_database_connection(self, db_name: str) -> create_engine:\n",
    "        \"\"\"Create database connection\"\"\"\n",
    "        host = 'localhost' if db_name == 'website_data' else '192.168.1.92'\n",
    "        return create_engine(\n",
    "            f\"postgresql://{self.config['user']}:{self.config['password']}@{host}/{db_name}\"\n",
    "        )\n",
    "\n",
    "    def extract_certificate_data(self, db_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Extract certificate data from database\"\"\"\n",
    "        self.logger.info(f\"Extracting certificate data from {db_name}\")\n",
    "        \n",
    "        engine = self.get_database_connection(db_name)\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            domain,\n",
    "            https_certificate_issuer,\n",
    "            https_certificate_domain,\n",
    "            https_certificate_expiry,\n",
    "            https_certificate_public_key,\n",
    "            https_certificate_signature_algorithm,\n",
    "            https_certificate_extensions,\n",
    "            https_certificate_body,\n",
    "            domain_registrar,\n",
    "            last_update,\n",
    "            whois_domain,\n",
    "            dig_info_a,\n",
    "            dig_info_mx,\n",
    "            dig_info_ns,\n",
    "            ip_organization\n",
    "        FROM website_data \n",
    "        WHERE status = 7 \n",
    "        AND https_certificate_issuer IS NOT NULL\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql_query(query, engine)\n",
    "\n",
    "    def _extract_basic_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract basic certificate features\"\"\"\n",
    "        return {\n",
    "            'total_certs': int(len(df)),\n",
    "            'issuer_distribution': df['https_certificate_issuer'].value_counts().to_dict(),\n",
    "            'algorithm_distribution': df['https_certificate_signature_algorithm'].value_counts().to_dict(),\n",
    "            'registrar_distribution': df['domain_registrar'].value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_temporal_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract temporal patterns and features\"\"\"\n",
    "        df['last_update'] = pd.to_datetime(df['last_update'])\n",
    "        \n",
    "        daily_counts = df.groupby(df['last_update'].dt.date).size()\n",
    "        monthly_counts = df.groupby([\n",
    "            df['last_update'].dt.year,\n",
    "            df['last_update'].dt.month\n",
    "        ]).size()\n",
    "        \n",
    "        return {\n",
    "            'daily_counts': {str(k): int(v) for k, v in daily_counts.items()},\n",
    "            'monthly_counts': {f\"{k[0]}-{k[1]}\": int(v) for k, v in monthly_counts.items()},\n",
    "            'weekday_distribution': df['last_update'].dt.dayofweek.value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_structural_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract structural certificate features\"\"\"\n",
    "        domain_levels = df['domain'].str.count(r'\\.') + 1\n",
    "        has_wildcard = df['https_certificate_domain'].str.contains(r'\\*', regex=True).fillna(False)\n",
    "        \n",
    "        return {\n",
    "            'domain_levels': domain_levels.value_counts().to_dict(),\n",
    "            'has_wildcard': has_wildcard.value_counts().to_dict(),\n",
    "            'cert_domain_match': df.apply(\n",
    "                lambda x: str(x['domain']).lower() in str(x['https_certificate_domain']).lower()\n",
    "                if pd.notnull(x['https_certificate_domain']) else False,\n",
    "                axis=1\n",
    "            ).value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_security_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract security-related features\"\"\"\n",
    "        key_strength = df['https_certificate_public_key'].apply(self._analyze_key_strength)\n",
    "        return {\n",
    "            'key_strength': [k for k in key_strength],\n",
    "            'is_self_signed': df['https_certificate_issuer'].str.contains(\n",
    "                'self signed', case=False\n",
    "            ).fillna(False).value_counts().to_dict(),\n",
    "            'uses_sha1': df['https_certificate_signature_algorithm'].str.contains(\n",
    "                'sha1', case=False\n",
    "            ).fillna(False).value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _analyze_key_strength(self, key_info: str) -> Dict:\n",
    "        \"\"\"Analyze public key strength\"\"\"\n",
    "        if pd.isna(key_info):\n",
    "            return {'type': 'unknown', 'strength': 0}\n",
    "            \n",
    "        key_info = str(key_info).upper()\n",
    "        \n",
    "        if 'RSA' in key_info:\n",
    "            match = re.search(r'(\\d+)\\s*(?:BIT|BITS)?', key_info)\n",
    "            return {\n",
    "                'type': 'RSA',\n",
    "                'strength': int(match.group(1)) if match else 0\n",
    "            }\n",
    "        elif any(ec in key_info for ec in ['EC', 'ECDSA']):\n",
    "            match = re.search(r'(\\d+)[Kk]?', key_info)\n",
    "            return {\n",
    "                'type': 'EC',\n",
    "                'strength': int(match.group(1)) if match else 0\n",
    "            }\n",
    "        \n",
    "        return {'type': 'unknown', 'strength': 0}\n",
    "\n",
    "    def analyze_certificates(self, db_name: str) -> Dict:\n",
    "        \"\"\"Perform comprehensive certificate analysis\"\"\"\n",
    "        self.logger.info(f\"Starting analysis for {db_name}\")\n",
    "        \n",
    "        try:\n",
    "            df = self.extract_certificate_data(db_name)\n",
    "            \n",
    "            features = {\n",
    "                'basic': self._extract_basic_features(df),\n",
    "                'temporal': self._extract_temporal_features(df),\n",
    "                'structural': self._extract_structural_features(df),\n",
    "                'security': self._extract_security_features(df)\n",
    "            }\n",
    "            \n",
    "            self._save_processed_data(features, db_name)\n",
    "            self._generate_visualizations(features, db_name)\n",
    "            \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing certificates for {db_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _process_for_serialization(self, obj: Any) -> Any:\n",
    "        \"\"\"Process objects for JSON serialization\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            return {str(k): self._process_for_serialization(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (pd.Series, pd.DataFrame)):\n",
    "            return obj.to_dict()\n",
    "        elif isinstance(obj, (np.integer, np.floating)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (date, datetime)):\n",
    "            return str(obj)\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [self._process_for_serialization(x) for x in obj]\n",
    "        return obj\n",
    "\n",
    "    def _save_processed_data(self, features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Save processed data to files\"\"\"\n",
    "        try:\n",
    "            output_path = self.data_dir / f'cert_features_{db_name}_{self.timestamp}.json'\n",
    "            processed_features = self._process_for_serialization(features)\n",
    "            \n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(processed_features, f, indent=2, default=str)\n",
    "                \n",
    "            self.logger.info(f\"Saved processed data to {output_path}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving processed data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _generate_visualizations(self, features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Generate and save visualizations\"\"\"\n",
    "        try:\n",
    "            self._plot_temporal_patterns(features['temporal'], db_name)\n",
    "            self._plot_security_patterns(features['security'], db_name)\n",
    "            self._plot_structural_patterns(features['structural'], db_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error generating visualizations: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _plot_temporal_patterns(self, temporal_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create temporal analysis plots\"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        monthly_data = {\n",
    "            datetime.strptime(k, \"%Y-%m\"): v \n",
    "            for k, v in temporal_features['monthly_counts'].items()\n",
    "        }\n",
    "        dates = sorted(monthly_data.keys())\n",
    "        counts = [monthly_data[date] for date in dates]\n",
    "        \n",
    "        plt.plot(range(len(counts)), counts)\n",
    "        plt.title(f'Monthly Certificate Counts - {db_name}')\n",
    "        plt.xlabel('Month Index')\n",
    "        plt.ylabel('Number of Certificates')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'temporal_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_security_patterns(self, security_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create security analysis plots\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        key_strengths = [x['strength'] for x in security_features['key_strength'] if x['strength'] > 0]\n",
    "        if key_strengths:\n",
    "            plt.hist(key_strengths, bins=20, edgecolor='black')\n",
    "            plt.title(f'Key Strength Distribution - {db_name}')\n",
    "            plt.xlabel('Key Strength (bits)')\n",
    "            plt.ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'security_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_structural_patterns(self, structural_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create structural analysis plots\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        levels = list(structural_features['domain_levels'].keys())\n",
    "        counts = list(structural_features['domain_levels'].values())\n",
    "        \n",
    "        plt.bar(levels, counts)\n",
    "        plt.title(f'Domain Level Distribution - {db_name}')\n",
    "        plt.xlabel('Domain Levels')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'structural_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc252db3-be5d-40be-90be-5fea4621a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5934ec6e-5465-4979-b9df-41eee9b774cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2769267-f070-4779-b2a9-725119fd6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceeb86ba-35f6-49b4-ba23-9bea81194313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCertificateAnalyzer:\n",
    "    \"\"\"Advanced SSL certificate analyzer with comprehensive feature extraction and analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str):\n",
    "        \"\"\"Initialize the analyzer with configuration and setup\"\"\"\n",
    "        self.setup_environment(config_path)\n",
    "        self.setup_logging()\n",
    "        \n",
    "    def setup_environment(self, config_path: str) -> None:\n",
    "        \"\"\"Setup analysis environment and load configuration\"\"\"\n",
    "        with open(config_path) as f:\n",
    "            self.config = json.load(f)['database']\n",
    "            \n",
    "        self.base_dir = Path('/home/asomura/waseda/nextstep/RAPIDS')\n",
    "        self.output_dir = self.base_dir / 'reports' / 'certificate_analysis'\n",
    "        self.data_dir = self.base_dir / 'data' / 'processed'\n",
    "        \n",
    "        for dir_path in [self.output_dir, self.data_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "    def setup_logging(self) -> None:\n",
    "        \"\"\"Configure logging settings\"\"\"\n",
    "        log_dir = self.base_dir / 'data' / 'logs'\n",
    "        log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        logging.basicConfig(\n",
    "            filename=log_dir / f'advanced_cert_analysis_{self.timestamp}.log',\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def get_database_connection(self, db_name: str) -> create_engine:\n",
    "        \"\"\"Create database connection\"\"\"\n",
    "        host = 'localhost' if db_name == 'website_data' else '192.168.1.92'\n",
    "        return create_engine(\n",
    "            f\"postgresql://{self.config['user']}:{self.config['password']}@{host}/{db_name}\"\n",
    "        )\n",
    "\n",
    "    def extract_certificate_data(self, db_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Extract certificate data from database\"\"\"\n",
    "        self.logger.info(f\"Extracting certificate data from {db_name}\")\n",
    "        \n",
    "        engine = self.get_database_connection(db_name)\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            domain,\n",
    "            https_certificate_issuer,\n",
    "            https_certificate_domain,\n",
    "            https_certificate_expiry,\n",
    "            https_certificate_public_key,\n",
    "            https_certificate_signature_algorithm,\n",
    "            https_certificate_extensions,\n",
    "            https_certificate_body,\n",
    "            domain_registrar,\n",
    "            last_update,\n",
    "            whois_domain,\n",
    "            dig_info_a,\n",
    "            dig_info_mx,\n",
    "            dig_info_ns,\n",
    "            ip_organization\n",
    "        FROM website_data \n",
    "        WHERE status = 7 \n",
    "        AND https_certificate_issuer IS NOT NULL\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql_query(query, engine)\n",
    "\n",
    "    def _extract_basic_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract basic certificate features\"\"\"\n",
    "        return {\n",
    "            'total_certs': int(len(df)),\n",
    "            'issuer_distribution': df['https_certificate_issuer'].value_counts().to_dict(),\n",
    "            'algorithm_distribution': df['https_certificate_signature_algorithm'].value_counts().to_dict(),\n",
    "            'registrar_distribution': df['domain_registrar'].value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_temporal_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract temporal patterns and features\"\"\"\n",
    "        df['last_update'] = pd.to_datetime(df['last_update'])\n",
    "        \n",
    "        daily_counts = df.groupby(df['last_update'].dt.date).size()\n",
    "        monthly_counts = df.groupby([\n",
    "            df['last_update'].dt.year,\n",
    "            df['last_update'].dt.month\n",
    "        ]).size()\n",
    "        \n",
    "        return {\n",
    "            'daily_counts': {str(k): int(v) for k, v in daily_counts.items()},\n",
    "            'monthly_counts': {f\"{k[0]}-{k[1]}\": int(v) for k, v in monthly_counts.items()},\n",
    "            'weekday_distribution': df['last_update'].dt.dayofweek.value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_structural_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract structural certificate features\"\"\"\n",
    "        domain_levels = df['domain'].str.count(r'\\.') + 1\n",
    "        has_wildcard = df['https_certificate_domain'].str.contains(r'\\*', regex=True).fillna(False)\n",
    "        \n",
    "        return {\n",
    "            'domain_levels': domain_levels.value_counts().to_dict(),\n",
    "            'has_wildcard': has_wildcard.value_counts().to_dict(),\n",
    "            'cert_domain_match': df.apply(\n",
    "                lambda x: str(x['domain']).lower() in str(x['https_certificate_domain']).lower()\n",
    "                if pd.notnull(x['https_certificate_domain']) else False,\n",
    "                axis=1\n",
    "            ).value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_security_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract security-related features\"\"\"\n",
    "        key_strength = df['https_certificate_public_key'].apply(self._analyze_key_strength)\n",
    "        return {\n",
    "            'key_strength': [k for k in key_strength],\n",
    "            'is_self_signed': df['https_certificate_issuer'].str.contains(\n",
    "                'self signed', case=False\n",
    "            ).fillna(False).value_counts().to_dict(),\n",
    "            'uses_sha1': df['https_certificate_signature_algorithm'].str.contains(\n",
    "                'sha1', case=False\n",
    "            ).fillna(False).value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _analyze_key_strength(self, key_info: str) -> Dict:\n",
    "        \"\"\"Analyze public key strength\"\"\"\n",
    "        if pd.isna(key_info):\n",
    "            return {'type': 'unknown', 'strength': 0}\n",
    "            \n",
    "        key_info = str(key_info).upper()\n",
    "        \n",
    "        if 'RSA' in key_info:\n",
    "            match = re.search(r'(\\d+)\\s*(?:BIT|BITS)?', key_info)\n",
    "            return {\n",
    "                'type': 'RSA',\n",
    "                'strength': int(match.group(1)) if match else 0\n",
    "            }\n",
    "        elif any(ec in key_info for ec in ['EC', 'ECDSA']):\n",
    "            match = re.search(r'(\\d+)[Kk]?', key_info)\n",
    "            return {\n",
    "                'type': 'EC',\n",
    "                'strength': int(match.group(1)) if match else 0\n",
    "            }\n",
    "        \n",
    "        return {'type': 'unknown', 'strength': 0}\n",
    "\n",
    "    def analyze_certificates(self, db_name: str) -> Dict:\n",
    "        \"\"\"Perform comprehensive certificate analysis\"\"\"\n",
    "        self.logger.info(f\"Starting analysis for {db_name}\")\n",
    "        \n",
    "        try:\n",
    "            df = self.extract_certificate_data(db_name)\n",
    "            \n",
    "            features = {\n",
    "                'basic': self._extract_basic_features(df),\n",
    "                'temporal': self._extract_temporal_features(df),\n",
    "                'structural': self._extract_structural_features(df),\n",
    "                'security': self._extract_security_features(df)\n",
    "            }\n",
    "            \n",
    "            self._save_processed_data(features, db_name)\n",
    "            self._generate_visualizations(features, db_name)\n",
    "            \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing certificates for {db_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _process_for_serialization(self, obj: Any) -> Any:\n",
    "        \"\"\"Process objects for JSON serialization\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            return {str(k): self._process_for_serialization(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (pd.Series, pd.DataFrame)):\n",
    "            return obj.to_dict()\n",
    "        elif isinstance(obj, (np.integer, np.floating)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (date, datetime)):\n",
    "            return str(obj)\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [self._process_for_serialization(x) for x in obj]\n",
    "        return obj\n",
    "\n",
    "    def _save_processed_data(self, features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Save processed data to files\"\"\"\n",
    "        try:\n",
    "            output_path = self.data_dir / f'cert_features_{db_name}_{self.timestamp}.json'\n",
    "            processed_features = self._process_for_serialization(features)\n",
    "            \n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(processed_features, f, indent=2, default=str)\n",
    "                \n",
    "            self.logger.info(f\"Saved processed data to {output_path}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving processed data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _generate_visualizations(self, features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Generate and save visualizations\"\"\"\n",
    "        try:\n",
    "            self._plot_temporal_patterns(features['temporal'], db_name)\n",
    "            self._plot_security_patterns(features['security'], db_name)\n",
    "            self._plot_structural_patterns(features['structural'], db_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error generating visualizations: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _plot_temporal_patterns(self, temporal_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create temporal analysis plots\"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        monthly_data = {\n",
    "            datetime.strptime(k, \"%Y-%m\"): v \n",
    "            for k, v in temporal_features['monthly_counts'].items()\n",
    "        }\n",
    "        dates = sorted(monthly_data.keys())\n",
    "        counts = [monthly_data[date] for date in dates]\n",
    "        \n",
    "        plt.plot(range(len(counts)), counts)\n",
    "        plt.title(f'Monthly Certificate Counts - {db_name}')\n",
    "        plt.xlabel('Month Index')\n",
    "        plt.ylabel('Number of Certificates')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'temporal_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_security_patterns(self, security_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create security analysis plots\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        key_strengths = [x['strength'] for x in security_features['key_strength'] if x['strength'] > 0]\n",
    "        if key_strengths:\n",
    "            plt.hist(key_strengths, bins=20, edgecolor='black')\n",
    "            plt.title(f'Key Strength Distribution - {db_name}')\n",
    "            plt.xlabel('Key Strength (bits)')\n",
    "            plt.ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'security_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_structural_patterns(self, structural_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create structural analysis plots\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        levels = list(structural_features['domain_levels'].keys())\n",
    "        counts = list(structural_features['domain_levels'].values())\n",
    "        \n",
    "        plt.bar(levels, counts)\n",
    "        plt.title(f'Domain Level Distribution - {db_name}')\n",
    "        plt.xlabel('Domain Levels')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'structural_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4ba7b1-c596-4e61-8963-fb0724c8b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae2b32b-95ef-478d-ac69-b350e54ec631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c4a844-3e4e-48c5-8fac-070a14471822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Set up default plotting style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c3b6e0-6194-4552-b708-ef7d12b4af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCertificateAnalyzer:\n",
    "    \"\"\"Advanced SSL certificate analyzer with comprehensive feature extraction and analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str):\n",
    "        \"\"\"Initialize the analyzer with configuration and setup\"\"\"\n",
    "        self.setup_environment(config_path)\n",
    "        self.setup_logging()\n",
    "        \n",
    "    def setup_environment(self, config_path: str) -> None:\n",
    "        \"\"\"Setup analysis environment and load configuration\"\"\"\n",
    "        with open(config_path) as f:\n",
    "            self.config = json.load(f)['database']\n",
    "            \n",
    "        self.base_dir = Path('/home/asomura/waseda/nextstep/RAPIDS')\n",
    "        self.output_dir = self.base_dir / 'reports' / 'certificate_analysis'\n",
    "        self.data_dir = self.base_dir / 'data' / 'processed'\n",
    "        \n",
    "        for dir_path in [self.output_dir, self.data_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "    def setup_logging(self) -> None:\n",
    "        \"\"\"Configure logging settings\"\"\"\n",
    "        log_dir = self.base_dir / 'data' / 'logs'\n",
    "        log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        logging.basicConfig(\n",
    "            filename=log_dir / f'advanced_cert_analysis_{self.timestamp}.log',\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def get_database_connection(self, db_name: str) -> create_engine:\n",
    "        \"\"\"Create database connection\"\"\"\n",
    "        host = 'localhost' if db_name == 'website_data' else '192.168.1.92'\n",
    "        return create_engine(\n",
    "            f\"postgresql://{self.config['user']}:{self.config['password']}@{host}/{db_name}\"\n",
    "        )\n",
    "\n",
    "    def extract_certificate_data(self, db_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Extract certificate data from database\"\"\"\n",
    "        self.logger.info(f\"Extracting certificate data from {db_name}\")\n",
    "        \n",
    "        engine = self.get_database_connection(db_name)\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            domain,\n",
    "            https_certificate_issuer,\n",
    "            https_certificate_domain,\n",
    "            https_certificate_expiry,\n",
    "            https_certificate_public_key,\n",
    "            https_certificate_signature_algorithm,\n",
    "            https_certificate_extensions,\n",
    "            https_certificate_body,\n",
    "            domain_registrar,\n",
    "            last_update,\n",
    "            whois_domain,\n",
    "            dig_info_a,\n",
    "            dig_info_mx,\n",
    "            dig_info_ns,\n",
    "            ip_organization\n",
    "        FROM website_data \n",
    "        WHERE status = 7 \n",
    "        AND https_certificate_issuer IS NOT NULL\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql_query(query, engine)\n",
    "\n",
    "    def _extract_basic_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract basic certificate features\"\"\"\n",
    "        return {\n",
    "            'total_certs': int(len(df)),\n",
    "            'issuer_distribution': df['https_certificate_issuer'].value_counts().to_dict(),\n",
    "            'algorithm_distribution': df['https_certificate_signature_algorithm'].value_counts().to_dict(),\n",
    "            'registrar_distribution': df['domain_registrar'].value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_temporal_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract temporal patterns and features\"\"\"\n",
    "        df['last_update'] = pd.to_datetime(df['last_update'])\n",
    "        \n",
    "        daily_counts = df.groupby(df['last_update'].dt.date).size()\n",
    "        monthly_counts = df.groupby([\n",
    "            df['last_update'].dt.year,\n",
    "            df['last_update'].dt.month\n",
    "        ]).size()\n",
    "        \n",
    "        return {\n",
    "            'daily_counts': {str(k): int(v) for k, v in daily_counts.items()},\n",
    "            'monthly_counts': {f\"{k[0]}-{k[1]}\": int(v) for k, v in monthly_counts.items()},\n",
    "            'weekday_distribution': df['last_update'].dt.dayofweek.value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_structural_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract structural certificate features\"\"\"\n",
    "        domain_levels = df['domain'].str.count(r'\\.') + 1\n",
    "        has_wildcard = df['https_certificate_domain'].str.contains(r'\\*', regex=True).fillna(False)\n",
    "        \n",
    "        return {\n",
    "            'domain_levels': domain_levels.value_counts().to_dict(),\n",
    "            'has_wildcard': has_wildcard.value_counts().to_dict(),\n",
    "            'cert_domain_match': df.apply(\n",
    "                lambda x: str(x['domain']).lower() in str(x['https_certificate_domain']).lower()\n",
    "                if pd.notnull(x['https_certificate_domain']) else False,\n",
    "                axis=1\n",
    "            ).value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _extract_security_features(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Extract security-related features\"\"\"\n",
    "        key_strength = df['https_certificate_public_key'].apply(self._analyze_key_strength)\n",
    "        return {\n",
    "            'key_strength': [k for k in key_strength],\n",
    "            'is_self_signed': df['https_certificate_issuer'].str.contains(\n",
    "                'self signed', case=False\n",
    "            ).fillna(False).value_counts().to_dict(),\n",
    "            'uses_sha1': df['https_certificate_signature_algorithm'].str.contains(\n",
    "                'sha1', case=False\n",
    "            ).fillna(False).value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "    def _analyze_key_strength(self, key_info: str) -> Dict:\n",
    "        \"\"\"Analyze public key strength\"\"\"\n",
    "        if pd.isna(key_info):\n",
    "            return {'type': 'unknown', 'strength': 0}\n",
    "            \n",
    "        key_info = str(key_info).upper()\n",
    "        \n",
    "        if 'RSA' in key_info:\n",
    "            match = re.search(r'(\\d+)\\s*(?:BIT|BITS)?', key_info)\n",
    "            return {\n",
    "                'type': 'RSA',\n",
    "                'strength': int(match.group(1)) if match else 0\n",
    "            }\n",
    "        elif any(ec in key_info for ec in ['EC', 'ECDSA']):\n",
    "            match = re.search(r'(\\d+)[Kk]?', key_info)\n",
    "            return {\n",
    "                'type': 'EC',\n",
    "                'strength': int(match.group(1)) if match else 0\n",
    "            }\n",
    "        \n",
    "        return {'type': 'unknown', 'strength': 0}\n",
    "\n",
    "    def analyze_certificates(self, db_name: str) -> Dict:\n",
    "        \"\"\"Perform comprehensive certificate analysis\"\"\"\n",
    "        self.logger.info(f\"Starting analysis for {db_name}\")\n",
    "        \n",
    "        try:\n",
    "            df = self.extract_certificate_data(db_name)\n",
    "            \n",
    "            features = {\n",
    "                'basic': self._extract_basic_features(df),\n",
    "                'temporal': self._extract_temporal_features(df),\n",
    "                'structural': self._extract_structural_features(df),\n",
    "                'security': self._extract_security_features(df)\n",
    "            }\n",
    "            \n",
    "            self._save_processed_data(features, db_name)\n",
    "            self._generate_visualizations(features, db_name)\n",
    "            \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing certificates for {db_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _process_for_serialization(self, obj: Any) -> Any:\n",
    "        \"\"\"Process objects for JSON serialization\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            return {str(k): self._process_for_serialization(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (pd.Series, pd.DataFrame)):\n",
    "            return obj.to_dict()\n",
    "        elif isinstance(obj, (np.integer, np.floating)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (date, datetime)):\n",
    "            return str(obj)\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [self._process_for_serialization(x) for x in obj]\n",
    "        return obj\n",
    "\n",
    "    def _save_processed_data(self, features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Save processed data to files\"\"\"\n",
    "        try:\n",
    "            output_path = self.data_dir / f'cert_features_{db_name}_{self.timestamp}.json'\n",
    "            processed_features = self._process_for_serialization(features)\n",
    "            \n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(processed_features, f, indent=2, default=str)\n",
    "                \n",
    "            self.logger.info(f\"Saved processed data to {output_path}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving processed data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _generate_visualizations(self, features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Generate and save visualizations\"\"\"\n",
    "        try:\n",
    "            self._plot_temporal_patterns(features['temporal'], db_name)\n",
    "            self._plot_security_patterns(features['security'], db_name)\n",
    "            self._plot_structural_patterns(features['structural'], db_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error generating visualizations: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _plot_temporal_patterns(self, temporal_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create temporal analysis plots\"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        monthly_data = {\n",
    "            datetime.strptime(k, \"%Y-%m\"): v \n",
    "            for k, v in temporal_features['monthly_counts'].items()\n",
    "        }\n",
    "        dates = sorted(monthly_data.keys())\n",
    "        counts = [monthly_data[date] for date in dates]\n",
    "        \n",
    "        plt.plot(range(len(counts)), counts)\n",
    "        plt.title(f'Monthly Certificate Counts - {db_name}')\n",
    "        plt.xlabel('Month Index')\n",
    "        plt.ylabel('Number of Certificates')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'temporal_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_security_patterns(self, security_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create security analysis plots\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        key_strengths = [x['strength'] for x in security_features['key_strength'] if x['strength'] > 0]\n",
    "        if key_strengths:\n",
    "            plt.hist(key_strengths, bins=20, edgecolor='black')\n",
    "            plt.title(f'Key Strength Distribution - {db_name}')\n",
    "            plt.xlabel('Key Strength (bits)')\n",
    "            plt.ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'security_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_structural_patterns(self, structural_features: Dict, db_name: str) -> None:\n",
    "        \"\"\"Create structural analysis plots\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        levels = list(structural_features['domain_levels'].keys())\n",
    "        counts = list(structural_features['domain_levels'].values())\n",
    "        \n",
    "        plt.bar(levels, counts)\n",
    "        plt.title(f'Domain Level Distribution - {db_name}')\n",
    "        plt.xlabel('Domain Levels')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / f'structural_analysis_{db_name}_{self.timestamp}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544050f-b33e-410a-ba00-562b99a2eba1",
   "metadata": {},
   "source": [
    "# メイン実行部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbf9fc29-b113-49cf-a085-ff81b9269da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing website_data...\n",
      "\n",
      "Analysis Results for website_data:\n",
      "Total certificates: 10974\n",
      "\n",
      "Top certificate issuers:\n",
      "- R11: 2923\n",
      "- R10: 2526\n",
      "- R3: 1026\n",
      "- GTS CA 1D4: 805\n",
      "- E5: 547\n",
      "\n",
      "Analyzing normal_sites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2368/3235380401.py:98: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  has_wildcard = df['https_certificate_domain'].str.contains(r'\\*', regex=True).fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Results for normal_sites:\n",
      "Total certificates: 9591\n",
      "\n",
      "Top certificate issuers:\n",
      "- WE1: 1789\n",
      "- R11: 958\n",
      "- R10: 931\n",
      "- Amazon RSA 2048 M02: 478\n",
      "- Amazon RSA 2048 M03: 443\n"
     ]
    }
   ],
   "source": [
    "# Configuration and execution\n",
    "config_path = \"/home/asomura/waseda/nextstep/RAPIDS/config/database.json\"\n",
    "analyzer = AdvancedCertificateAnalyzer(config_path)\n",
    "\n",
    "# Analyze both databases\n",
    "results = {}\n",
    "for db_name in ['website_data', 'normal_sites']:\n",
    "    try:\n",
    "        print(f\"\\nAnalyzing {db_name}...\")\n",
    "        results[db_name] = analyzer.analyze_certificates(db_name)\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(f\"\\nAnalysis Results for {db_name}:\")\n",
    "        print(f\"Total certificates: {results[db_name]['basic']['total_certs']}\")\n",
    "        print(\"\\nTop certificate issuers:\")\n",
    "        for issuer, count in sorted(\n",
    "            results[db_name]['basic']['issuer_distribution'].items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )[:5]:\n",
    "            print(f\"- {issuer}: {count}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {db_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd57d7-2047-4ccf-8ec5-7094b224226a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
